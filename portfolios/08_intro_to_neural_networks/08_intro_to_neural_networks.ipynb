{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfc141f5",
   "metadata": {},
   "source": [
    "This portfolio contains information from Matt William's course [Introduction to Neural Networks](https://milliams.com/courses/neural_networks/).\n",
    "\n",
    "# Introduction to neural networks\n",
    "\n",
    "Neural networks are a type of machine learning model that are inspired by the human brain. Artificial neurons are a simplification of biological neurons -- they take in multiple inputs and pass on their output to multiple other neurons. A neuron's value is determined by the sum of its inputs ($x_i$), which are weighted by the strength of the connection between the neurons ($w_i$): $$p = \\sum_i x_i w_i$$\n",
    "This value $p$ is then passed through an activation function $\\phi$ to determine the neuron's output $o$: $$o = \\phi(p) = \\phi\\left(\\sum_i x_i w_i\\right)$$\n",
    "This activation function step allows neural networks to model non-linear relationships.\n",
    "\n",
    "\n",
    "Most neural networks have the following architecture:\n",
    "\n",
    "![Diagram from [Introduction to Neural Networks](https://milliams.com/courses/neural_networks/Neural%20Networks.html)](./images/nn_architecture.png)\n",
    "\n",
    "The input layer typically takes on values from the user / data. There are then a number of hidden layers, which are made up of neurons that take in the input layer's values and pass on their output to the next layer. The output layer then takes in the output of the last hidden layer and produces the final output of the network.\n",
    "\n",
    "Deciding the shape of a neural network is not an exact science. Typically, the size of the hidden layers is similar to the size of the input and output layers. The number of hidden layers represents the level of abstraction the network can learn.\n",
    "\n",
    "# Training a neural network\n",
    "\n",
    "Neural networks are most commonly trained using backpropagation. Initial weights can be set randomly. We define a loss function that measures how far off the network's output is from the true value. We then calculate the derivative of the loss function with respect to the weights and adjust the weights accordingly. \n",
    "\n",
    "# Python environments\n",
    "\n",
    "Python environments are a copy of Python plus the packages you need. You can create a new environment using Anaconda Navigator by clicking on the `Environments` tab and then `Create`. You can then search for and select the packages you need. For this portfolio, we need `tensorflow`, `tensorflow-datasets`, `scikit-learn`, `scikit-image`, `jupyterlab`, and `pandas`.\n",
    "\n",
    "# Convolutional neural networks\n",
    "\n",
    "Convolutional neural networks (CNNs) are a class of neural networks primarily used for image recognition and processing tasks. They leverage image kernel convolution by applying series of learned filters across input images. Through layers of of filters, CNNs can efficiently extract relevant features, e.g. edges, enabling them to recognize patterns and objects within images.\n",
    "\n",
    "CNNs typically contain three types of layers:\n",
    "\n",
    "+ Convolutional layers: consist of a set of convolution filters, also known as kernels, to the image. The convolution operation involves sliding the filter over the input image, computing the element-wise product between the filter and the corresponding patch of the input, and summing the results to generate a single value in the output feature map.\n",
    "+ Pooling layers: downsample the resulting image data, resulting in decreased dimensionality and thus lower computing time and lower risk of overfitting. A common method of pooling is known as max pooling, where the maximum value within a fixed window is retained while discarding the rest.\n",
    "+ Dense (fully connected) layers: perform classification on the features extracted after convolution and pooling. These are traditional neural network layers where every neuron is connected to every neuron in the preceding layer.\n",
    "\n",
    "# MNIST example\n",
    "\n",
    "We will show an example application using CNNs on the MNIST dataset, which is a dataset consisting of 70,000 28×28 pixel images of handwritten digits.\n",
    "\n",
    "## Designing the CNN\n",
    "\n",
    "1. First convolutional layer: consists of 16 5×5 filters (layer size = 28×28×16=12544)\n",
    "2. First pooling layer: reduces the image by a factor of 2 in all directions (layer size = 14×14×16=3136)\n",
    "3. Second convolutional layer: consists of 32 5×5 filters (layer size = 14×14×32=6272)\n",
    "4. Second pooling layer: reduces the image by a factor of 2 in all directions (layer size = 7×7×32=1568)\n",
    "5. Dense layer: fully-connected layer of 128 nodes\n",
    "6. Output layer: 10 neurons corresponding to the 10 classes (digits from 0-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82819e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-10 11:29:29.767248: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-10 11:29:29.830014: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-10 11:29:29.830054: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-10 11:29:29.831377: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-10 11:29:29.841945: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-10 11:29:32.340975: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-10 11:29:32.391204: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-10 11:29:32.391469: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-10 11:29:32.395012: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-10 11:29:32.395249: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-10 11:29:32.395410: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-10 11:29:32.485899: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-10 11:29:32.486152: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-10 11:29:32.486337: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-10 11:29:32.486477: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1583 MB memory:  -> device: 0, name: NVIDIA GeForce MX550, pci bus id: 0000:02:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    # first convolutional layer\n",
    "    tf.keras.layers.Conv2D( # layer for 2-dimensional image\n",
    "        filters=16,\n",
    "        kernel_size=5,\n",
    "        padding=\"same\", # what to put on the edges\n",
    "        activation=tf.nn.relu\n",
    "    ),\n",
    "    # first pooling layer\n",
    "    tf.keras.layers.MaxPool2D((2, 2), (2, 2), padding=\"same\"),\n",
    "    # second convolutional layer\n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size=5,\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu\n",
    "    ),\n",
    "    # second pooling layer\n",
    "    tf.keras.layers.MaxPool2D((2, 2), (2, 2), padding=\"same\"),\n",
    "    # flatten layer into a linear set of nodes\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # add a fully connected layer of 128 nodes\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    # use drop-out regularization to randomly ignore 40% of the nodes each training cycle\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    # output layer\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c111b6",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "We will train the model using sparse categorical cross-entropy for the loss function. This loss function is well-suited to situations where we have more than two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9af18edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d6d524-0cb7-418e-b108-4cd44e6993b6",
   "metadata": {},
   "source": [
    "Next, we load the data and split it into training and test sets. The resulting training and test sets are sequences of 28×28×1 matrices containing the numbers 0-255, each with a label from 0-9 indicating which number is in the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3075060-bd1e-4f66-8d9d-d7a421f01a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aw23877/anaconda3/envs/nn/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "ds_train_orig, ds_test_orig = tfds.load(\n",
    "    \"mnist\",\n",
    "    split=[\"train\", \"test\"],\n",
    "    as_supervised=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f21d4f-822a-41a2-b460-ae0efc54fbf3",
   "metadata": {},
   "source": [
    "We need to convert our data from the range 0-255 to 0-1. Then we can shuffle the data and put it into batches of 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e4d3dea-1530-4bc2-825f-577fb40d94df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_img(image, label):\n",
    "    return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "ds_train = ds_train_orig.map(normalize_img)\n",
    "ds_train = ds_train.shuffle(1000).batch(128)\n",
    "\n",
    "ds_test = ds_test_orig.map(normalize_img)\n",
    "ds_test = ds_test.batch(128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b81815-329a-4387-85d8-b83ebc51ff88",
   "metadata": {},
   "source": [
    "Now we can fit the model to the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23d270e1-a858-4226-b387-67c6f72468fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-10 11:29:34.258062: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2024-05-10 11:29:35.538022: I external/local_xla/xla/service/service.cc:168] XLA service 0x7e6ae8765b20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-05-10 11:29:35.538082: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce MX550, Compute Capability 7.5\n",
      "2024-05-10 11:29:35.546907: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1715336975.629805   85734 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 8s 11ms/step - loss: 0.2560 - accuracy: 0.9211 - val_loss: 0.0611 - val_accuracy: 0.9792\n",
      "Epoch 2/2\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0742 - accuracy: 0.9780 - val_loss: 0.0391 - val_accuracy: 0.9871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7e6c0c4b1490>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_test,\n",
    "    epochs=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f4192a-6a1f-4d05-8ad1-f0d26af494c6",
   "metadata": {},
   "source": [
    "From the output of `fit`, we can see the following values for each epoch:\n",
    "\n",
    "+ loss: The value of the loss function calculated on the training data for the last batch in the epoch\n",
    "+ accuracy: The fraction of the entries in the training data set that are classified correctly\n",
    "+ val_loss: The value of the loss function calculated on the test data\n",
    "+ val_accuracy: The fraction of the entries in the test set that are classified correctly\n",
    "\n",
    "## Testing on real-world images\n",
    "\n",
    "We can now test the model on some additional real-world images. We have 10 images of 28x28 pixels apiece, with 1 color channel (black and white)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ada1683-b538-4f62-8f67-19323a43791e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 28, 28, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.request import urlretrieve\n",
    "\n",
    "for i in list(range(1,10)) + [\"dog\"]:\n",
    "    urlretrieve(f\"https://github.com/milliams/intro_deep_learning/raw/master/{i}.png\", f\"{i}.png\")\n",
    "\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "\n",
    "images = []\n",
    "for i in list(range(1,10)) + [\"dog\"]:\n",
    "    images.append(np.array(imread(f\"{i}.png\")/255.0, dtype=\"float32\"))\n",
    "images = np.array(images)[:,:,:,np.newaxis]\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd8d961-eb2b-451e-83a1-1d2fc3f26b2d",
   "metadata": {},
   "source": [
    "We can apply the model to these images to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c14206e7-16f2-4d7a-83ff-7040e1821d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 302ms/step\n",
      "1 at  3.9%. CNN thinks it's a 3 (43.6%)\n",
      "2 at 86.5%. CNN thinks it's a 2 (86.5%)\n",
      "3 at 30.3%. CNN thinks it's a 8 (48.6%)\n",
      "4 at  1.4%. CNN thinks it's a 3 (94.4%)\n",
      "5 at 100.0%. CNN thinks it's a 5 (100.0%)\n",
      "6 at  3.2%. CNN thinks it's a 5 (44.7%)\n",
      "7 at 55.5%. CNN thinks it's a 7 (55.5%)\n",
      "8 at 24.5%. CNN thinks it's a 3 (46.1%)\n",
      "9 at  1.6%. CNN thinks it's a 8 (78.0%)\n",
      "dog. CNN thinks it's a 2 (37.0%)\n"
     ]
    }
   ],
   "source": [
    "probabilities = model.predict(images)\n",
    "\n",
    "truths = list(range(1, 10)) + [\"dog\"]\n",
    "\n",
    "table = []\n",
    "for truth, probs in zip(truths, probabilities):\n",
    "    prediction = probs.argmax()\n",
    "    if truth == 'dog':\n",
    "        print(f\"{truth}. CNN thinks it's a {prediction} ({probs[prediction]*100:.1f}%)\")\n",
    "    else:\n",
    "        print(f\"{truth} at {probs[truth]*100:4.1f}%. CNN thinks it's a {prediction} ({probs[prediction]*100:4.1f}%)\")\n",
    "    table.append((truth, probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50caba8b-e994-4686-9ee4-c709a8c09eec",
   "metadata": {},
   "source": [
    "## Data augmentation\n",
    "\n",
    "We can see some issues in performance when we apply our model to real-world images that might not have the exact same image composition as our training data, which contained only white handwritten numbers on a black background. To address this, we can try some data augmentation strategies to create a wider range of input images. We will do so by adding color-inverted images to our training dataset and then retraining the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "373cb0c0-4f48-4ae6-aad6-3b36741080eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "938/938 [==============================] - 7s 8ms/step - loss: 0.0938 - accuracy: 0.9714 - val_loss: 0.1039 - val_accuracy: 0.9653\n",
      "Epoch 2/2\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.0587 - accuracy: 0.9820 - val_loss: 0.0605 - val_accuracy: 0.9800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7e6c0c289490>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function for inverting color of the image\n",
    "def invert_img(image, label):\n",
    "    return 1.-image, label\n",
    "\n",
    "ds_train_new = ds_train_orig.map(normalize_img)\n",
    "ds_train_new = ds_train_new.concatenate(ds_train_new.map(invert_img))  # add inverted images to training\n",
    "ds_train_new = ds_train_new.shuffle(1000)\n",
    "ds_train_new = ds_train_new.batch(128)\n",
    "\n",
    "ds_test_new = ds_test_orig.map(normalize_img)\n",
    "ds_test_new = ds_test_new.concatenate(ds_test_new.map(invert_img))  # add inverted images to testing\n",
    "ds_test_new = ds_test_new.batch(128)\n",
    "\n",
    "# Retrain the model:\n",
    "model.fit(\n",
    "    ds_train_new,\n",
    "    validation_data=ds_test_new,\n",
    "    epochs=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6c34f8-b347-4900-8235-f9b77d9b9c4e",
   "metadata": {},
   "source": [
    "We can now check to see if there is any improvement in the model's performance on the additional real-world images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1375f2e1-5d2c-464e-9f98-77a38dedaef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "1 at 11.9%. CNN thinks it's a 8 (18.4%)\n",
      "2 at 100.0%. CNN thinks it's a 2 (100.0%)\n",
      "3 at 100.0%. CNN thinks it's a 3 (100.0%)\n",
      "4 at 99.6%. CNN thinks it's a 4 (99.6%)\n",
      "5 at 98.5%. CNN thinks it's a 5 (98.5%)\n",
      "6 at 100.0%. CNN thinks it's a 6 (100.0%)\n",
      "7 at 98.7%. CNN thinks it's a 7 (98.7%)\n",
      "8 at 99.9%. CNN thinks it's a 8 (99.9%)\n",
      "9 at 18.6%. CNN thinks it's a 8 (41.4%)\n",
      "dog. CNN thinks it's a 8 (22.6%)\n"
     ]
    }
   ],
   "source": [
    "probabilities = model.predict(images)\n",
    "\n",
    "truths = list(range(1, 10)) + [\"dog\"]\n",
    "\n",
    "table = []\n",
    "for truth, probs in zip(truths, probabilities):\n",
    "    prediction = probs.argmax()\n",
    "    if truth == 'dog':\n",
    "        print(f\"{truth}. CNN thinks it's a {prediction} ({probs[prediction]*100:.1f}%)\")\n",
    "    else:\n",
    "        print(f\"{truth} at {probs[truth]*100:4.1f}%. CNN thinks it's a {prediction} ({probs[prediction]*100:4.1f}%)\")\n",
    "    table.append((truth, probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548ac3e1-d98a-4cd8-b635-9cef65016acb",
   "metadata": {},
   "source": [
    "We can see that the model still has trouble with the 1 and 9, but the model now correctly identifies the 2-4, 6, and 8."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
