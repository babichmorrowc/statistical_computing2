{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "db3aaea0-6cba-4238-9ea7-35819d01534c",
      "metadata": {
        "id": "db3aaea0-6cba-4238-9ea7-35819d01534c"
      },
      "source": [
        "1. First convolutional layer: consists of 16 5×5 filters (layer size = 28×28×16=12544)\n",
        "2. First pooling layer: reduces the image by a factor of 2 in all directions (layer size = 14×14×16=3136)\n",
        "3. Second convolutional layer: consists of 32 5×5 filters (layer size = 14×14×32=6272)\n",
        "4. Second pooling layer: reduces the image by a factor of 2 in all directions (layer size = 7×7×32=1568)\n",
        "5. Dense layer: fully-connected layer of 128 nodes\n",
        "6. Output layer: 10 neurons corresponding to the 10 classes (digits from 0-9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "544f433a-2010-415f-9e4b-27414489b188",
      "metadata": {
        "id": "544f433a-2010-415f-9e4b-27414489b188"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0802c8c3-8767-4fd6-9f3c-fc63fbe204ef",
      "metadata": {
        "id": "0802c8c3-8767-4fd6-9f3c-fc63fbe204ef"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    # first convolutional layer\n",
        "    tf.keras.layers.Conv2D( # layer for 2-dimensional image\n",
        "        filters=16,\n",
        "        kernel_size=5,\n",
        "        padding=\"same\", # what to put on the edges\n",
        "        activation=tf.nn.relu\n",
        "    ),\n",
        "    # first pooling layer\n",
        "    tf.keras.layers.MaxPool2D((2, 2), (2, 2), padding=\"same\"),\n",
        "    # second convolutional layer\n",
        "    tf.keras.layers.Conv2D(\n",
        "        filters=32,\n",
        "        kernel_size=5,\n",
        "        padding=\"same\",\n",
        "        activation=tf.nn.relu\n",
        "    ),\n",
        "    # second pooling layer\n",
        "    tf.keras.layers.MaxPool2D((2, 2), (2, 2), padding=\"same\"),\n",
        "    # flatten layer into a linear set of nodes\n",
        "    tf.keras.layers.Flatten(),\n",
        "    # add a fully connected layer of 128 nodes\n",
        "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "    # use drop-out regularization to randomly ignore 40% of the nodes each training cycle\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    # output layer\n",
        "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74325215-c4b1-4998-b2ea-d5c12c08ca34",
      "metadata": {
        "id": "74325215-c4b1-4998-b2ea-d5c12c08ca34"
      },
      "source": [
        "We will train the model using sparse categorical cross-entropy for the loss function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8899d841-61bc-45ee-80c3-b8b445c2d24d",
      "metadata": {
        "id": "8899d841-61bc-45ee-80c3-b8b445c2d24d"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c39ce606-c07e-4c0f-b060-30fdbf84c4da",
      "metadata": {
        "id": "c39ce606-c07e-4c0f-b060-30fdbf84c4da"
      },
      "source": [
        "We load the data and split it into training and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6bd07061-6fe6-4800-93ea-9f8fe94c038a",
      "metadata": {
        "id": "6bd07061-6fe6-4800-93ea-9f8fe94c038a"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "ds_train, ds_test = tfds.load(\n",
        "    \"mnist\",\n",
        "    split=[\"train\", \"test\"],\n",
        "    as_supervised=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to convert our data from the range 0-255 to 0-1. Then we can shuffle the data and put it into batches of 128."
      ],
      "metadata": {
        "id": "6SHBycQpFVtT"
      },
      "id": "6SHBycQpFVtT"
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_img(image, label):\n",
        "    return tf.cast(image, tf.float32) / 255., label\n",
        "\n",
        "ds_train = ds_train.map(normalize_img)\n",
        "ds_train = ds_train.shuffle(1000).batch(128)\n",
        "\n",
        "ds_test = ds_test.map(normalize_img)\n",
        "ds_test = ds_test.batch(128)"
      ],
      "metadata": {
        "id": "uoU9QpGTFlPS"
      },
      "id": "uoU9QpGTFlPS",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can fit the model to the data."
      ],
      "metadata": {
        "id": "t1EQGi-OF42x"
      },
      "id": "t1EQGi-OF42x"
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    ds_train,\n",
        "    validation_data=ds_test,\n",
        "    epochs=2,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jK9SOuUqF6Tf",
        "outputId": "5040c5ac-88de-491e-e25e-d1ca824e7590"
      },
      "id": "jK9SOuUqF6Tf",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "469/469 [==============================] - 68s 141ms/step - loss: 0.2513 - accuracy: 0.9207 - val_loss: 0.0551 - val_accuracy: 0.9822\n",
            "Epoch 2/2\n",
            "469/469 [==============================] - 61s 130ms/step - loss: 0.0713 - accuracy: 0.9789 - val_loss: 0.0364 - val_accuracy: 0.9876\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7cddfea29c60>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now test the model on some additional real-world images."
      ],
      "metadata": {
        "id": "CNkK7vTLG9Uv"
      },
      "id": "CNkK7vTLG9Uv"
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.request import urlretrieve\n",
        "\n",
        "for i in list(range(1,10)) + [\"dog\"]:\n",
        "    urlretrieve(f\"https://github.com/milliams/intro_deep_learning/raw/master/{i}.png\", f\"{i}.png\")\n",
        "\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "\n",
        "images = []\n",
        "for i in list(range(1,10)) + [\"dog\"]:\n",
        "    images.append(np.array(imread(f\"{i}.png\")/255.0, dtype=\"float32\"))\n",
        "images = np.array(images)[:,:,:,np.newaxis]\n",
        "images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lnk_1dCHAm6",
        "outputId": "fcaa42f8-977e-46ef-bb4c-26727debc8cd"
      },
      "id": "-lnk_1dCHAm6",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have 10 images of 28x28 pixels apiece, with 1 color channel (black and white).\n",
        "\n",
        "We can apply the model to these images to make predictions."
      ],
      "metadata": {
        "id": "TlZ9h7DGHRS1"
      },
      "id": "TlZ9h7DGHRS1"
    },
    {
      "cell_type": "code",
      "source": [
        "probabilities = model.predict(images)\n",
        "\n",
        "truths = list(range(1, 10)) + [\"dog\"]\n",
        "\n",
        "table = []\n",
        "for truth, probs in zip(truths, probabilities):\n",
        "    prediction = probs.argmax()\n",
        "    if truth == 'dog':\n",
        "        print(f\"{truth}. CNN thinks it's a {prediction} ({probs[prediction]*100:.1f}%)\")\n",
        "    else:\n",
        "        print(f\"{truth} at {probs[truth]*100:4.1f}%. CNN thinks it's a {prediction} ({probs[prediction]*100:4.1f}%)\")\n",
        "    table.append((truth, probs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MofSCplFHUEq",
        "outputId": "d34e8f45-7c78-4986-954a-e5eeecbdf0f9"
      },
      "id": "MofSCplFHUEq",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n",
            "1 at 13.0%. CNN thinks it's a 8 (38.9%)\n",
            "2 at 48.7%. CNN thinks it's a 2 (48.7%)\n",
            "3 at  5.2%. CNN thinks it's a 0 (54.2%)\n",
            "4 at 95.1%. CNN thinks it's a 4 (95.1%)\n",
            "5 at 99.0%. CNN thinks it's a 5 (99.0%)\n",
            "6 at  3.0%. CNN thinks it's a 3 (34.8%)\n",
            "7 at 45.4%. CNN thinks it's a 7 (45.4%)\n",
            "8 at 29.1%. CNN thinks it's a 8 (29.1%)\n",
            "9 at  2.9%. CNN thinks it's a 0 (40.1%)\n",
            "dog. CNN thinks it's a 8 (56.9%)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}